#!/usr/bin/env python3
"""
TeachProxy é•¿æ—¶é—´å‹åŠ›æµ‹è¯•

ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“é—¨ç”¨äºé•¿æ—¶é—´å›ºå®šè´Ÿè½½æµ‹è¯•ã€‚
ä¸ä½¿ç”¨ LoadTestShapeï¼Œç›´æ¥é€šè¿‡ --users å’Œ --run-time æ§åˆ¶ã€‚

Usage:
    # 20åˆ†é’Ÿæµ‹è¯•ï¼Œ100ç”¨æˆ·
    locust -f tests/stress/locustfile_long.py --headless \\
        --users 100 --spawn-rate 10 --run-time 20m \\
        --host=http://localhost:8000

    # 1å°æ—¶æµ‹è¯•
    locust -f tests/stress/locustfile_long.py --headless \\
        --users 50 --spawn-rate 5 --run-time 1h \\
        --host=http://localhost:8000
"""

import json
import os
import random
import time
from datetime import datetime
from typing import Any, Dict, List

from locust import HttpUser, task, between, events


# =============================================================================
# ç¯å¢ƒé…ç½®
# =============================================================================

# è®¾ç½® Mock Provider æ¨¡å¼
os.environ["TEACHPROXY_MOCK_PROVIDER"] = "true"
os.environ.pop("DEEPSEEK_API_KEY", None)
os.environ.pop("OPENAI_API_KEY", None)
os.environ["RATE_LIMIT_REQUESTS_PER_MINUTE"] = "10000"
os.environ["RATE_LIMIT_BURST_SIZE"] = "1000"


# =============================================================================
# æµ‹è¯•æ•°æ®
# =============================================================================

NORMAL_PROMPTS = [
    "Hello, how are you?",
    "What is Python?",
    "Explain recursion",
    "What is a function?",
    "How do I install packages?",
    "What's the difference between list and tuple?",
    "Explain decorators",
    "What is a class?",
]

RULE_TRIGGERED_PROMPTS = [
    "Write a sorting algorithm",
    "Code a calculator",
    "Generate a program",
    "Help me implement",
    "Give me the code for",
]

LONG_CONTEXT_PROMPTS = [
    "Explain Python decorators in detail with examples",
    "What are the best practices for error handling in Python?",
    "How does async/await work in Python?",
]


# =============================================================================
# Locust ç”¨æˆ·ç±»
# =============================================================================

class GatewayUser(HttpUser):
    """
    æ¨¡æ‹Ÿ TeachProxy ç½‘å…³ç”¨æˆ·

    ç”¨æˆ·è¡Œä¸ºåˆ†å¸ƒï¼š
    - 70% Normal Chat (æ™®é€šå¯¹è¯)
    - 20% Streaming Chat (æµå¼å“åº”)
    - 10% Rule Triggered (è§¦å‘è§„åˆ™)
    """

    wait_time = between(0.2, 1)
    _test_api_keys = []

    @classmethod
    def load_test_api_keys(cls):
        """ä»æ•°æ®åº“åŠ è½½æµ‹è¯• API keys"""
        if cls._test_api_keys:
            return

        import sys
        from pathlib import Path
        sys.path.insert(0, str(Path(__file__).parent.parent.parent))

        from gateway.app.core.config import settings
        from gateway.app.db.models import Student
        from sqlalchemy import create_engine
        from sqlalchemy.orm import sessionmaker

        engine = create_engine(settings.database_url.replace("+aiosqlite", "").replace("+pysqlite", ""))
        Session = sessionmaker(bind=engine)
        session = Session()

        try:
            students = session.query(Student).filter(
                Student.id.like("locust_test_%")
            ).order_by(Student.id.desc()).limit(200).all()

            for student in students:
                parts = student.id.split("_")
                if len(parts) >= 3:
                    index = parts[-1]
                    cls._test_api_keys.append(f"sk-stress-test-{index}")
        finally:
            session.close()

        print(f"[GatewayUser] Loaded {len(cls._test_api_keys)} test API keys")

    def on_start(self):
        """ç”¨æˆ·å¯åŠ¨æ—¶æ‰§è¡Œ"""
        if not self._test_api_keys:
            self.load_test_api_keys()

        user_index = id(self) % len(self._test_api_keys)
        api_key = self._test_api_keys[user_index]

        self.client.headers.update({
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        })
        self.client.timeout = 30

    @task(7)
    def normal_chat(self):
        """æ™®é€šèŠå¤©è¯·æ±‚ï¼ˆ70%æƒé‡ï¼‰"""
        prompt = random.choice(NORMAL_PROMPTS)
        self._do_chat_request(prompt, stream=False, request_type="normal")

    @task(2)
    def streaming_chat(self):
        """æµå¼èŠå¤©è¯·æ±‚ï¼ˆ20%æƒé‡ï¼‰"""
        prompt = random.choice(LONG_CONTEXT_PROMPTS)
        self._do_chat_request(prompt, stream=True, request_type="streaming")

    @task(1)
    def rule_triggered_chat(self):
        """è§¦å‘è§„åˆ™çš„è¯·æ±‚ï¼ˆ10%æƒé‡ï¼‰"""
        prompt = random.choice(RULE_TRIGGERED_PROMPTS)
        self._do_chat_request(prompt, stream=False, request_type="rule_triggered")

    def _do_chat_request(self, prompt: str, stream: bool, request_type: str):
        """æ‰§è¡ŒèŠå¤©è¯·æ±‚"""
        payload = {
            "model": "deepseek-chat",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": random.randint(100, 500),
            "temperature": random.uniform(0.5, 1.0),
            "stream": stream
        }

        with self.client.post(
            "/v1/chat/completions",
            json=payload,
            catch_response=True,
            name=f"/v1/chat/completions ({request_type})"
        ) as response:
            if response.status_code == 200:
                if stream:
                    for line in response.iter_lines():
                        if not line:
                            continue
                        line_str = line.decode('utf-8') if isinstance(line, bytes) else line
                        line_str = line_str.strip()
                        if line_str == "data: [DONE]":
                            break
                        if line_str.startswith("data: "):
                            try:
                                data = json.loads(line_str[6:])
                                if data.get("choices"):
                                    content = data["choices"][0].get("delta", {}).get("content", "")
                            except:
                                pass
                else:
                    try:
                        data = response.json()
                        if "choices" not in data:
                            response.failure(f"Invalid response: {data}")
                    except:
                        response.failure("Invalid JSON response")
            elif response.status_code == 429:
                response.success()
            else:
                response.failure(f"HTTP {response.status_code}")


# =============================================================================
# äº‹ä»¶å¤„ç†å™¨ - æµ‹è¯•ç»“æœç»Ÿè®¡
# =============================================================================

@events.request.add_listener
def on_request(request_type, name, response_time, response_length, exception, **kwargs):
    """è¯·æ±‚å®Œæˆäº‹ä»¶ - è®°å½•è¯¦ç»†æŒ‡æ ‡"""
    if exception:
        print(f"[ERROR] {name}: {exception}")


@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """æµ‹è¯•ç»“æŸäº‹ä»¶ - ç”Ÿæˆæ‘˜è¦"""
    stats = environment.stats

    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•å®Œæˆæ‘˜è¦")
    print("=" * 60)
    print(f"æ€»è¯·æ±‚æ•°: {stats.total.num_requests}")
    print(f"å¤±è´¥è¯·æ±‚: {stats.total.num_failures}")
    print(f"æˆåŠŸç‡: {(1 - stats.total.fail_ratio) * 100:.2f}%")
    print(f"å¹³å‡å“åº”æ—¶é—´: {stats.total.avg_response_time:.0f}ms")
    print(f"ä¸­ä½æ•°å“åº”æ—¶é—´: {stats.total.median_response_time:.0f}ms")
    print(f"P95 å“åº”æ—¶é—´: {stats.total.get_response_time_percentile(0.95):.0f}ms")
    print(f"RPS: {stats.total.total_rps:.2f}")
    print("=" * 60)
